---
algorithm: "Continuous Skill Space"
version: "guided"
layer_size: 256
replay_buffer_size: 10000

algorithm_kwargs:
  num_epochs: 400
  num_eval_steps_per_epoch: 5000
  num_trains_per_train_loop: 10
  num_expl_steps_per_train_loop: 10
  min_num_steps_before_training: 1000
  max_path_length: 1000
  batch_size: 1024

trainer_kwargs:
  discount: 0.99
  soft_target_tau: 0.005
  target_update_period: 1
  policy_lr: 0.0003
  qf_lr: 0.0003
  reward_scale: 1
  use_automatic_entropy_tuning: True
  df_lr_step: 0.001
  df_lr_seq: 0.001

seq_len: 100
skill_dim: 2
hidden_size_rnn: 2
hidden_sizes_df: [30, 30]
feature_decode_hidden_size_df: [30, 30]

info_loss:
  alpha: 0.99
  lamda: 0.2
