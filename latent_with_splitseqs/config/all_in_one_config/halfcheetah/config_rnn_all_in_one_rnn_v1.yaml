---
algorithm: "Continuous Skill Space"
version: "latent split seq | guided | sac in feature space | rnn only"
layer_size: 256
replay_buffer_size: 100000
random_hp_tuning: False

env_kwargs:
  env_id: halfcheetah
  exclude_current_positions_from_observation: False

obs_dims_used_policy_all_except: [0,]

algorithm_kwargs:
  num_epochs: 500
  num_eval_steps_per_epoch: 1000
  num_trains_per_train_loop: 200
  num_expl_steps_per_train_loop: 10
  min_num_steps_before_training: 400
  max_path_length: 1000
  batch_size: 1000

trainer_kwargs:
  discount: 0.99
  soft_target_tau: 0.005
  target_update_period: 1
  policy_lr: 0.0003
  qf_lr: 0.0003
  reward_scale: 1
  use_automatic_entropy_tuning: True
  df_lr: 0.001
  train_sac_in_feature_space: True

seq_len: 40
horizon_len: 400
skill_dim: 2

df_evaluation_env:
  obs_dims_to_log: [0, 1]
  action_dims_to_log: [0, 1]
  seq_len: 40
  horizon_len: 400
  plot_skill_influence:
    obs: True
    action: True
    obs_one_plot: True
    plot_post: True

df_evaluation_memory:
  seq_len: 40
  horizon_len: 400
  batch_size: 100

info_loss:
  alpha: 0.7
  lamda: 0.0

df_type:
  feature_extractor: rnn
  rnn_type: normal
  latent_type: full_seq
  recon: end_only

latent_kwargs:
  None: null

latent_kwargs_smoothing:
  None: null

latent_single_layer_kwargs:
  None: null

rnn_kwargs:
  hidden_size_rnn: 10
  bidirectional: False

df_kwargs_rnn:
  obs_dims_used: [1, 2, 3, 4, 5, 6, 7, 8, 9]
  obs_dims_used_except: null
  dropout: 0.4
  leaky_slope_classifier: 0.2
  hidden_units_classifier: [256, 256]
  std_classifier: null

df_kwargs_latent:
  None: null

test_script_path: [/home/michael/EIT/Github_Repos/24_SelfSupervisedDevel/cont_skillspace_test/main_test_guided_normal_plot.py,
                   /home/michael/EIT/Github_Repos/24_SelfSupervisedDevel/cont_skillspace_test/main_test_guided_normal_render.py]
log_folder: logshalfcheetah
log_interval: 10
